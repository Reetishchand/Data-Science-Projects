{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML Assign 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HlJTjNA74i5",
        "outputId": "e16d56a9-088a-4759-f986-078c7dbeb6eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class NeuralNetwork:\n",
        "    def __init__(self):\n",
        "        np.random.seed(1)\n",
        "        self.W1 = np.random.rand(8, 3)\n",
        "        self.W2 = np.random.rand(4, 2)\n",
        "        self.W3 = np.random.rand(3, 1)\n",
        "        self.inputLayerNeurons  = 0\n",
        "\n",
        "    def minMaxScaling(self, data):\n",
        "        minX,maxX = np.min(data), np.max(data)\n",
        "        difference = maxX - minX\n",
        "        for index in range(data.shape[0]):\n",
        "            data[index] = (data[index] - minX) / difference\n",
        "        return data\n",
        "\n",
        "    def meanScaling(self, data):\n",
        "        meanArray = np.mean(data)\n",
        "        sdArray = np.std(data)\n",
        "        for index in range(data.shape[0]):\n",
        "            data[index] = (data[index] - meanArray) / sdArray\n",
        "        return data\n",
        "\n",
        "    def sacleAndProcessData(self, data, featureLabels):\n",
        "        for label in featureLabels:\n",
        "            data[:, featureLabels[label]] = self.minMaxScaling(data[:, featureLabels[label]])\n",
        "        return data\n",
        "\n",
        "    def sigmoidActivationFunction(self, x):\n",
        "        val = 1 / (1 + np.exp(-x, dtype=np.float64))\n",
        "        val = np.minimum(val, 0.9999)\n",
        "        val = np.maximum(val, 0.0001)\n",
        "        return val\n",
        "\n",
        "    def tahHActivationFunction(self, x):\n",
        "        val = (2 * self.sigmoidActivationFunction(2 * x)) - 1\n",
        "        return val\n",
        "\n",
        "    def reluActivationFunction(self, x):\n",
        "        return np.maximum(0, x)\n",
        "\n",
        "    def forwardPass(self, X, activationFunction):\n",
        "        layer1 = np.dot(X, self.W1)\n",
        "        h = self.selectActivationFunction(activationFunction, layer1)\n",
        "        layer1WithBias = np.insert(h, 0, 1, axis=1)\n",
        "        layer2 = np.dot(layer1WithBias, self.W2)\n",
        "        h = self.selectActivationFunction(activationFunction, layer2)\n",
        "        layer2WithBias = np.insert(h, 0, 1, axis=1)\n",
        "        layer3 = np.dot(layer2WithBias, self.W3)\n",
        "        return layer1WithBias, layer2WithBias, self.selectActivationFunction(activationFunction, layer3)\n",
        "\n",
        "    def selectActivationFunction(self, activationFunction, net):\n",
        "        if activationFunction.lower() == \"tanh\".lower():\n",
        "            return self.tahHActivationFunction(net)\n",
        "        elif activationFunction.lower() == \"ReLu\".lower():\n",
        "            return self.reluActivationFunction(net)\n",
        "        else:\n",
        "            return self.sigmoidActivationFunction(net)\n",
        "\n",
        "    def calculateDelta(self, error, net, activationFunction):\n",
        "        if activationFunction.lower() == \"sigmoid\".lower():\n",
        "            return self.calculateDeltaForSigmoidFunction(error, net)\n",
        "        elif activationFunction.lower() == \"tanh\".lower():\n",
        "            return self.calculateDeltaForTanHFunction(error, net)\n",
        "        elif activationFunction.lower() == \"ReLu\".lower():\n",
        "            return self.calculateDeltaForReLuFunction(error, net)\n",
        "\n",
        "    def calculateDeltaForSigmoidFunction(self, error, net):\n",
        "        delta = np.multiply(np.multiply(net, (1 - net), dtype=np.float64), error)\n",
        "        return delta\n",
        "\n",
        "    def calculateDeltaForTanHFunction(self, error, net):\n",
        "        delta = np.multiply(1 - np.square(net, dtype=np.float64), error)\n",
        "        return delta\n",
        "\n",
        "    def calculateDeltaForReLuFunction(self, error, net):\n",
        "        return np.where(net <= 0, 0, error)\n",
        "\n",
        "    def train(self, trainData, testData, epoch=1000, learningrate=0.00001, activationFunction='sigmoid',\n",
        "              plotGraph=False):\n",
        "\n",
        "        nrowsTrain, ncolsTrain = trainData.shape[0], trainData.shape[1]\n",
        "        trainX = trainData[:, 0:(ncolsTrain - 1)]\n",
        "        trainY = trainData[:, (ncolsTrain - 1)].reshape(nrowsTrain, 1)\n",
        "\n",
        "        nrowsTest, ncolsTest = testData.shape[0], testData.shape[1]\n",
        "        testX = testData[:, 0:(ncolsTest - 1)]\n",
        "        testY = testData[:, (ncolsTest - 1)].reshape(nrowsTest, 1)\n",
        "\n",
        "        mse = np.empty([1])\n",
        "        iterations = np.empty([1])\n",
        "        for count in range(epoch):\n",
        "            layer1, layer2, predictTrain = self.forwardPass(trainX, activationFunction)\n",
        "            error = trainY - predictTrain\n",
        "            meanSquareError = 0.5 * np.dot(np.transpose(error), error)\n",
        "            deltaOutputLayer = self.calculateDelta(error, predictTrain, activationFunction)\n",
        "            delta1, delta2, delta3 = self.backwardPass(trainX, deltaOutputLayer, learningrate\n",
        "                                                       , layer1, layer2, activationFunction)\n",
        "            self.W1 = self.W1 + delta1\n",
        "            self.W2 = self.W2 + delta2\n",
        "            self.W3 = self.W3 + delta3\n",
        "            mse = np.append(mse, meanSquareError)\n",
        "            iterations = np.append(iterations, count)\n",
        "\n",
        "        if plotGraph:\n",
        "            iterations = np.delete(iterations, 0)\n",
        "            mse = np.delete(mse, 0)\n",
        "            plt.plot(iterations, mse, linestyle='-', marker='o')\n",
        "            plt.xlabel(\"Iteration\")\n",
        "            plt.ylabel(\"Mean Square Error\")\n",
        "            plt.show()\n",
        "\n",
        "        trainLayer1, trainLayer2, predictionTrain = self.forwardPass(trainX, activationFunction)\n",
        "        trainError = trainY - predictionTrain\n",
        "        meanSquareErrorTrain = 0.5 * np.dot(np.transpose(trainError), trainError)\n",
        "        testLayer1, testLayer2, predictionTest = self.forwardPass(testX, activationFunction)\n",
        "        test_error = testY - predictionTest\n",
        "        meanSquareErrorTest = 0.5 * np.dot(np.transpose(test_error), test_error)\n",
        "        #print(\"Mean Square Error Train : \", meanSquareErrorTrain, \", Mean Square Error Test : \",\n",
        "             # meanSquareErrorTest)\n",
        "        return meanSquareErrorTrain[0][0], meanSquareErrorTest[0][0]\n",
        "\n",
        "\n",
        "\n",
        "    def backwardPass(self, X, deltaOutputLayer, learningrate, layer1, layer2, activationFunction):\n",
        "        deltaW2 = np.dot(self.W3, deltaOutputLayer.T)\n",
        "        deltaW2 = np.sum(deltaW2, axis=1).reshape(3, 1)\n",
        "        netOutput = []\n",
        "        if activationFunction.lower() == \"sigmoid\".lower():\n",
        "            netOutput = np.sum(np.multiply(layer2, (1 - layer2), dtype=np.float64),\n",
        "                               axis=0).reshape(3, 1)\n",
        "        elif activationFunction.lower() == \"tanh\".lower():\n",
        "            netOutput = np.sum((1 - np.square(layer2, dtype=np.float64)), axis=0).reshape(3, 1)\n",
        "        elif activationFunction.lower() == \"ReLu\".lower():\n",
        "            netOutput = np.sum(np.where(layer2 <= 0, 0, layer2), axis=0).reshape(3, 1)\n",
        "\n",
        "        deltaLayer2 = np.multiply(netOutput, deltaW2, dtype=np.float64)\n",
        "        deltsLayer2Temp = np.delete(deltaLayer2, (0), axis=0)\n",
        "        deltaW1 = np.dot(self.W2, deltsLayer2Temp)\n",
        "        netOutputTemp = []\n",
        "        if activationFunction.lower() == \"sigmoid\".lower():\n",
        "            netOutputTemp = np.sum(np.multiply(layer1, (1 - layer1), dtype=np.float64),\n",
        "                                   axis=0).reshape(4, 1)\n",
        "        elif activationFunction.lower() == \"tanh\".lower():\n",
        "            netOutputTemp = np.sum((1 - np.square(layer1, dtype=np.float64)), axis=0).reshape(4, 1)\n",
        "        elif activationFunction.lower() == \"ReLu\".lower():\n",
        "            netOutputTemp = np.sum(np.where(layer1 <= 0, 0, layer1), axis=0).reshape(4, 1)\n",
        "\n",
        "        deltaLayer1 = np.multiply(netOutputTemp, deltaW1, dtype=np.float64)\n",
        "        deltaLayer1Temp = np.delete(deltaLayer1, (0), axis=0)\n",
        "        layer2[:, 0] = np.multiply(layer2[:, 0].reshape(layer2.shape[0], 1),\n",
        "                                   deltaOutputLayer).flatten()\n",
        "        layer2[:, 1] = np.multiply(layer2[:, 1].reshape(layer2.shape[0], 1),\n",
        "                                   deltaOutputLayer).flatten()\n",
        "        layer2[:, 2] = np.multiply(layer2[:, 2].reshape(layer2.shape[0], 1),\n",
        "                                   deltaOutputLayer).flatten()\n",
        "        deltaW = layer2 * learningrate\n",
        "        deltaW = np.sum(deltaW, axis=0).reshape(3, 1)\n",
        "        layer1 = np.sum(layer1, axis=0).reshape(4, 1)\n",
        "        netProaductDelta2 = np.dot(layer1, deltsLayer2Temp.T)\n",
        "        deltaW2 = netProaductDelta2 * learningrate\n",
        "        inputLayer = np.sum(X, axis=0).reshape(self.inputLayerNeurons , 1)\n",
        "        netProductInputLayer = np.dot(inputLayer, deltaLayer1Temp.T)\n",
        "        deltaW1 = netProductInputLayer * learningrate\n",
        "        return deltaW1, deltaW2, deltaW\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Select the Activation Function to be implemented \\n 1. Sigmoid \\n 2. Tanh \\n 3. ReLu\")\n",
        "    inp = int(input())\n",
        "    if inp == 1:\n",
        "        activationFunction = \"sigmoid\"\n",
        "    elif inp == 2:\n",
        "        activationFunction = \"tanh\"\n",
        "    else:\n",
        "        activationFunction = \"relu\"\n",
        "    datasetURL ='https://cs6375assignments.s3.amazonaws.com/assignments/Assignment-2/winequality-red.csv'\n",
        "    plotGraph = True\n",
        "    df = pd.read_csv(datasetURL, ';')\n",
        "    correlations = df.corr()\n",
        "    print(correlations)\n",
        "    # f = plt.figure(figsize=(19, 15))\n",
        "    # plt.matshow(correlations, fignum=f.number)\n",
        "    # plt.xticks(range(df.shape[1]), df.columns, fontsize=14, rotation=45)\n",
        "    # plt.yticks(range(df.shape[1]), df.columns, fontsize=14)\n",
        "    # cb = plt.colorbar()  \n",
        "    # cb.ax.tick_params(labelsize=14)\n",
        "    # plt.title('Correlation Matrix', fontsize=16);   \n",
        "    cols = df.columns\n",
        "    columnsToBeRemovedSet = set([])\n",
        "    for i in range(0, correlations.shape[0]):\n",
        "        for j in range(0, correlations.shape[1]):\n",
        "          if (float(correlations.iloc[i][j]) > 0.7 or float(correlations.iloc[i][j]) < -0.7) and i != j:\n",
        "            print(cols[i], \" | \", cols[j], \" \\t | \", correlations.iloc[i][j])\n",
        "    columnsToDrop = ['citric acid','free sulfur dioxide','fixed acidity']\n",
        "    print(\"Dropping Unwanted Columns : \")\n",
        "    print(columnsToDrop)\n",
        "    df = df.drop(columns=columnsToDrop)\n",
        "    featureLabels = {}\n",
        "    columns = df.columns\n",
        "    for i in range(len(columns)):\n",
        "        featureLabels[columns[i]] = i\n",
        "    print(\"Feature Labels --> \", featureLabels)\n",
        "    data = df.iloc[:, :].values.reshape(df.shape[0], df.shape[1])\n",
        "    myNeuralNetwork = NeuralNetwork()\n",
        "    myNeuralNetwork.inputLayerNeurons = len(featureLabels)-1\n",
        "    myNeuralNetwork.W1 = np.random.rand(myNeuralNetwork.inputLayerNeurons, 3)\n",
        "    data = myNeuralNetwork.sacleAndProcessData(data, featureLabels)\n",
        "    indices = np.random.permutation(data.shape[0])\n",
        "    trainingIndices, testIndices = indices[:int((data.shape[0] * 0.8))], indices[int((data.shape[0] * 0.8)):]\n",
        "    trainingData, testData = data[trainingIndices, :], data[testIndices, :]\n",
        "    epoch = 1000\n",
        "    lr = 0.001\n",
        "    globalW1 = myNeuralNetwork.W1\n",
        "    globalW2 = myNeuralNetwork.W2\n",
        "    globalW3 = myNeuralNetwork.W3\n",
        "    meanSquareErrorTrain, meanSquareErrorTest=myNeuralNetwork.train(trainingData,testData,epoch, lr,activationFunction,plotGraph)\n",
        "\n",
        "    #Driver Code to find Observations:\n",
        "\n",
        "    # epochList = [1,19,57,175,553,999,5043,9999]\n",
        "    # lrList =[0.01,0.001,0.003,0.006,0.009,0.0001,0.0004,0.0007]\n",
        "    # count = 1\n",
        "    # results=[]\n",
        "    # for activationFunction in [\"sigmoid\", \"tanh\", \"relu\"]:\n",
        "    #     for epoch in epochList:\n",
        "    #         for lr in lrList:\n",
        "    #             meanSquareErrorTrain, meanSquareErrorTest=myNeuralNetwork.train(trainingData,testData,epoch, lr,activationFunction,False)\n",
        "    #             row={}\n",
        "    #             row[\"SNo.\"]=count\n",
        "    #             row[\"Activation Function\"]=activationFunction\n",
        "    #             row[\"Epoch\"]=epoch\n",
        "    #             row[\"Learning Rate\"]=lr\n",
        "    #             row[\"Mean Square Error Train\"]=meanSquareErrorTrain\n",
        "    #             row[\"Mean Square Error Test\"]=meanSquareErrorTest\n",
        "    #             row[\"Difference\"] = meanSquareErrorTrain-meanSquareErrorTest\n",
        "    #             results.append(row)\n",
        "    #             count+=1\n",
        "    # df = pd.DataFrame(results)\n",
        "    # df.to_excel(\"observations.xlsx\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Select the Activation Function to be implemented \n",
            " 1. Sigmoid \n",
            " 2. Tanh \n",
            " 3. ReLu\n",
            "1\n",
            "                      fixed acidity  volatile acidity  ...   alcohol   quality\n",
            "fixed acidity              1.000000         -0.256131  ... -0.061668  0.124052\n",
            "volatile acidity          -0.256131          1.000000  ... -0.202288 -0.390558\n",
            "citric acid                0.671703         -0.552496  ...  0.109903  0.226373\n",
            "residual sugar             0.114777          0.001918  ...  0.042075  0.013732\n",
            "chlorides                  0.093705          0.061298  ... -0.221141 -0.128907\n",
            "free sulfur dioxide       -0.153794         -0.010504  ... -0.069408 -0.050656\n",
            "total sulfur dioxide      -0.113181          0.076470  ... -0.205654 -0.185100\n",
            "density                    0.668047          0.022026  ... -0.496180 -0.174919\n",
            "pH                        -0.682978          0.234937  ...  0.205633 -0.057731\n",
            "sulphates                  0.183006         -0.260987  ...  0.093595  0.251397\n",
            "alcohol                   -0.061668         -0.202288  ...  1.000000  0.476166\n",
            "quality                    0.124052         -0.390558  ...  0.476166  1.000000\n",
            "\n",
            "[12 rows x 12 columns]\n",
            "Dropping Unwanted Columns : \n",
            "['citric acid', 'free sulfur dioxide', 'fixed acidity']\n",
            "Feature Labels -->  {'volatile acidity': 0, 'residual sugar': 1, 'chlorides': 2, 'total sulfur dioxide': 3, 'density': 4, 'pH': 5, 'sulphates': 6, 'alcohol': 7, 'quality': 8}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11wICNS-78VJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}